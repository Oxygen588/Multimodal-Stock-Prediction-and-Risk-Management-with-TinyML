{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "db = sqlite3.connect(\"./data_gatherer/fintime.db\",check_same_thread=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = db.cursor()\n",
    "cursor.execute(\"SELECT ticker,dataJSON FROM stockData\")\n",
    "stockData = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "company_descriptions = {}\n",
    "\n",
    "with open(\"./data_gatherer/company_descriptions.json\") as f:\n",
    "    company_descriptions = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "data = []\n",
    "for row in stockData:\n",
    "    dataaa = json.loads(row[1])\n",
    "    dataaa['ticker'] = row[0]\n",
    "    data.append(dataaa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "def getDataForDaysHistorical(hist, daysStart, daysEnd):\n",
    "    midPoint = int(len(hist) / 2)\n",
    "    startIndex = midPoint + daysStart\n",
    "    endIndex = midPoint + daysEnd\n",
    "    data = hist[startIndex:endIndex]\n",
    "    return data, hist[midPoint]\n",
    "\n",
    "def getDaysFrumCurrentD(hist):\n",
    "    midPoint = int(len(hist) / 2)\n",
    "\n",
    "    return hist[midPoint][\"Date\"]\n",
    "\n",
    "def getDaysFrumCurrent(hist):\n",
    "        date_str = getDaysFrumCurrentD(hist)\n",
    "        date_obj = datetime.strptime(date_str, \"%Y-%m-%d\")\n",
    "        current_date = datetime.now()\n",
    "        difference = (current_date - date_obj).days\n",
    "        return difference\n",
    "\n",
    "\n",
    "def getLowestLow(hist):\n",
    "    lowest = hist[0][\"Low\"]\n",
    "    for day in hist:\n",
    "        if day[\"Low\"] < lowest:\n",
    "            lowest = day[\"Low\"]\n",
    "    return lowest\n",
    "def getDividends(hist):\n",
    "    dividends = 0\n",
    "    for day in hist:\n",
    "        if day[\"Dividends\"] != 0:\n",
    "            dividends += day[\"Dividends\"]\n",
    "    return dividends\n",
    "def getHighestHigh(hist):\n",
    "    highest = hist[0][\"High\"]\n",
    "    for day in hist:\n",
    "        if day[\"High\"] > highest:\n",
    "            highest = day[\"High\"]\n",
    "    return highest\n",
    "\n",
    "\n",
    "def getLowAndHighForDays(hist, start, end):\n",
    "    newHist,midpoint = getDataForDaysHistorical(hist, start, end)\n",
    "    return getLowestLow(newHist), getHighestHigh(newHist),getDividends(newHist),midpoint[\"Date\"]\n",
    "\n",
    "def getDataForPercentageRange(hist, startPercent, endPercent):\n",
    "    midPoint = len(hist) // 2\n",
    "    startIndex = midPoint + int(midPoint * startPercent / 100)\n",
    "    endIndex = midPoint + int(midPoint * endPercent / 100)\n",
    "    startIndex = max(0, startIndex)\n",
    "    endIndex = min(len(hist), endIndex)\n",
    "    data = hist[startIndex:endIndex]\n",
    "    return getHighestHigh(data), getLowestLow(data), getDividends(data)\n",
    "\n",
    "print(getDaysFrumCurrent(data[0][\"hist\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getDataForPercentageRange(data[0][\"hist\"],-50,-20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err=0\n",
    "for dataP in data:\n",
    "        try:\n",
    "            getDataForPercentageRange(dataP[\"hist\"], -100, -80)[0]\n",
    "            getDataForPercentageRange(dataP[\"hist\"], -80, -60)[1]\n",
    "            getDataForPercentageRange(dataP[\"hist\"], -60, -40)[0]\n",
    "            getDataForPercentageRange(dataP[\"hist\"], -60, -40)[1]\n",
    "            getDataForPercentageRange(dataP[\"hist\"], -40, -20)[0]\n",
    "            getDataForPercentageRange(dataP[\"hist\"], -40, -20)[1]\n",
    "            getDataForPercentageRange(dataP[\"hist\"], -20, -0)[0]\n",
    "            getDataForPercentageRange(dataP[\"hist\"], -20, -0)[1]\n",
    "\n",
    "            getDataForPercentageRange(dataP[\"hist\"], 0, 20)\n",
    "            getDataForPercentageRange(dataP[\"hist\"], 0, 100)\n",
    "        except:\n",
    "              err+=1\n",
    "              data.remove(dataP)\n",
    "err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newData=[]\n",
    "results = []\n",
    "for company in data:\n",
    "        result = []\n",
    "        extra = company.get(\"extra\", {})\n",
    "        \n",
    "        # Extract numeric features from 'extra' section\n",
    "        fiscal_year = extra.get(\"Fiscal Year\", {})\n",
    "        profitability = extra.get(\"Profitability\", {})\n",
    "        management = extra.get(\"Management Effectiveness\", {})\n",
    "        income_statement = extra.get(\"Income Statement\", {})\n",
    "        balance_sheet = extra.get(\"Balance Sheet\", {})\n",
    "        cash_flow = extra.get(\"Cash Flow Statement\", {})\n",
    "        stock_history = extra.get(\"Stock Price History\", {})\n",
    "        share_stats = extra.get(\"Share Statistics\", {})\n",
    "        dividends_splits = extra.get(\"Dividends & Splits\", {})\n",
    "        \n",
    "        result = [\n",
    "            company.get(\"current_price\", 0) or -1,\n",
    "            company.get(\"Market Cap\", 0) or -1,\n",
    "            company.get(\"Enterprise Value\", 0) or -1,\n",
    "            company.get(\"Trailing P/E\", 0) or -1,\n",
    "            company.get(\"Forward P/E\", 0) or -1,\n",
    "            company.get(\"PEG Ratio (5yr expected)\", 0) or -1,\n",
    "            company.get(\"Price/Sales\", 0) or -1,\n",
    "            company.get(\"Price/Book\", 0) or -1,\n",
    "            company.get(\"Enterprise Value/Revenue\", 0) or -1,\n",
    "            company.get(\"Enterprise Value/EBITDA\", 0) or -1,\n",
    "            getDataForPercentageRange(company.get(\"hist\"), -100, -80)[0],\n",
    "            getDataForPercentageRange(company.get(\"hist\"), -80, -60)[1],\n",
    "            getDataForPercentageRange(company.get(\"hist\"), -60, -40)[0],\n",
    "            getDataForPercentageRange(company.get(\"hist\"), -60, -40)[1],\n",
    "            getDataForPercentageRange(company.get(\"hist\"), -40, -20)[0],\n",
    "            getDataForPercentageRange(company.get(\"hist\"), -40, -20)[1],\n",
    "            getDataForPercentageRange(company.get(\"hist\"), -20, -0)[0],\n",
    "            getDataForPercentageRange(company.get(\"hist\"), -20, -0)[1],\n",
    "\n",
    "            float(profitability.get(\"Profit Margin\", -1)) if profitability.get(\"Profit Margin\") is not None else -1.0,\n",
    "            float(profitability.get(\"Operating Margin  (ttm)\", -1)) if profitability.get(\"Operating Margin  (ttm)\") is not None else -1.0,\n",
    "            # Management Effectiveness\n",
    "            float(management.get(\"Return on Assets  (ttm)\", -1)) if management.get(\"Return on Assets  (ttm)\") is not None else -1.0,\n",
    "            float(management.get(\"Return on Equity  (ttm)\", -1)) if management.get(\"Return on Equity  (ttm)\") is not None else -1.0,\n",
    "            # Income Statement\n",
    "            float(income_statement.get(\"Revenue  (ttm)\", 0)) if income_statement.get(\"Revenue  (ttm)\") is not None else -1.0,\n",
    "            float(income_statement.get(\"Revenue Per Share  (ttm)\", 0)) if income_statement.get(\"Revenue Per Share  (ttm)\") is not None else -1.0,\n",
    "            float(income_statement.get(\"Quarterly Revenue Growth  (yoy)\", 0)) if income_statement.get(\"Quarterly Revenue Growth  (yoy)\") is not None else -1.0,\n",
    "            float(income_statement.get(\"Gross Profit  (ttm)\", 0)) if income_statement.get(\"Gross Profit  (ttm)\") is not None else -1.0,\n",
    "            float(income_statement.get(\"EBITDA\", 0)) if income_statement.get(\"EBITDA\") is not None else -1.0,\n",
    "            float(income_statement.get(\"Net Income Avi to Common  (ttm)\", 0)) if income_statement.get(\"Net Income Avi to Common  (ttm)\") is not None else -1.0,\n",
    "            float(income_statement.get(\"Diluted EPS  (ttm)\", 0)) if income_statement.get(\"Diluted EPS  (ttm)\") is not None else -1.0,\n",
    "            float(income_statement.get(\"Quarterly Earnings Growth  (yoy)\", 0)) if income_statement.get(\"Quarterly Earnings Growth  (yoy)\") is not None else -1.0,\n",
    "            # Balance Sheet\n",
    "            float(balance_sheet.get(\"Total Cash  (mrq)\", 0)) if balance_sheet.get(\"Total Cash  (mrq)\") is not None else -1.0,\n",
    "            float(balance_sheet.get(\"Total Cash Per Share  (mrq)\", 0)) if balance_sheet.get(\"Total Cash Per Share  (mrq)\") is not None else -1.0,\n",
    "            float(balance_sheet.get(\"Total Debt  (mrq)\", 0)) if balance_sheet.get(\"Total Debt  (mrq)\") is not None else -1.0,\n",
    "            float(balance_sheet.get(\"Total Debt/Equity  (mrq)\", 0)) if balance_sheet.get(\"Total Debt/Equity  (mrq)\") is not None else -1.0,\n",
    "            float(balance_sheet.get(\"Current Ratio  (mrq)\", 0)) if balance_sheet.get(\"Current Ratio  (mrq)\") is not None else -1.0,\n",
    "            float(balance_sheet.get(\"Book Value Per Share  (mrq)\", 0)) if balance_sheet.get(\"Book Value Per Share  (mrq)\") is not None else -1.0,\n",
    "            # Cash Flow Statement\n",
    "            float(cash_flow.get(\"Operating Cash Flow  (ttm)\", 0)) if cash_flow.get(\"Operating Cash Flow  (ttm)\") is not None else -1.0,\n",
    "            float(cash_flow.get(\"Levered Free Cash Flow  (ttm)\", 0)) if cash_flow.get(\"Levered Free Cash Flow  (ttm)\") is not None else -1.0,\n",
    "            # Stock Price History\n",
    "            float(stock_history.get(\"Beta (5Y Monthly)\", 0)) if stock_history.get(\"Beta (5Y Monthly)\") is not None else -1.0,\n",
    "            float(stock_history.get(\"52 Week Range3\", 0)) if stock_history.get(\"52 Week Range3\") is not None else -1.0,\n",
    "            float(stock_history.get(\"S&P 500 52-Week Change3\", 0)) if stock_history.get(\"S&P 500 52-Week Change3\") is not None else -1.0,\n",
    "            float(stock_history.get(\"52 Week High3\", 0)) if stock_history.get(\"52 Week High3\") is not None else -1.0,\n",
    "            float(stock_history.get(\"52 Week Low3\", 0)) if stock_history.get(\"52 Week Low3\") is not None else -1.0,\n",
    "            float(stock_history.get(\"50-Day Moving Average3\", 0)) if stock_history.get(\"50-Day Moving Average3\") is not None else -1.0,\n",
    "            float(stock_history.get(\"200-Day Moving Average3\", 0)) if stock_history.get(\"200-Day Moving Average3\") is not None else -1.0,\n",
    "            # Share Statistics\n",
    "            float(share_stats.get(\"Avg Vol (3 month)3\", 0)) if share_stats.get(\"Avg Vol (3 month)3\") is not None else -1.0,\n",
    "            float(share_stats.get(\"Avg Vol (10 day)3\", 0)) if share_stats.get(\"Avg Vol (10 day)3\") is not None else -1.0,\n",
    "            float(share_stats.get(\"Shares Outstanding5\", 0)) if share_stats.get(\"Shares Outstanding5\") is not None else -1.0,\n",
    "            float(share_stats.get(\"Implied Shares Outstanding6\", 0)) if share_stats.get(\"Implied Shares Outstanding6\") is not None else -1.0,\n",
    "            float(share_stats.get(\"Float8\", 0)) if share_stats.get(\"Float8\") is not None else -1.0,\n",
    "            float(share_stats.get(\"% Held by Insiders1\", 0)) if share_stats.get(\"% Held by Insiders1\") is not None else -1.0,\n",
    "            float(share_stats.get(\"% Held by Institutions1\", 0)) if share_stats.get(\"% Held by Institutions1\") is not None else -1.0,\n",
    "            float(share_stats.get(\"Shares Short (12/31/2024)4\", 0)) if share_stats.get(\"Shares Short (12/31/2024)4\") is not None else -1.0,\n",
    "            float(share_stats.get(\"Short Ratio (12/31/2024)4\", 0)) if share_stats.get(\"Short Ratio (12/31/2024)4\") is not None else -1.0,\n",
    "            float(share_stats.get(\"Short % of Float (12/31/2024)4\", 0)) if share_stats.get(\"Short % of Float (12/31/2024)4\") is not None else -1.0,\n",
    "            float(share_stats.get(\"Short % of Shares Outstanding (12/31/2024)4\", 0)) if share_stats.get(\"Short % of Shares Outstanding (12/31/2024)4\") is not None else -1.0,\n",
    "            float(share_stats.get(\"Shares Short (prior month 11/29/2024)4\", 0)) if share_stats.get(\"Shares Short (prior month 11/29/2024)4\") is not None else -1.0,\n",
    "        ]\n",
    "        for feature in result:\n",
    "            if feature == -1:\n",
    "                result.remove(feature)\n",
    "        if len(result)>52:\n",
    "            newData.append(company)\n",
    "        results.append(len(result))\n",
    "print(results[0:25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "\n",
    "\n",
    "mean = statistics.mean(results)\n",
    "std_dev = statistics.stdev(results)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(results, 'bo-', label='Data Points') \n",
    "plt.axhline(mean, color='r', linestyle='--', label=f'Mean ({mean:.2f})')\n",
    "plt.axhline(mean + std_dev, color='g', linestyle=':', label=f'Mean +/- 1 SD ({std_dev:.2f})')\n",
    "plt.axhline(mean - std_dev, color='g', linestyle=':')\n",
    "\n",
    "plt.title('Data Points with Mean and Standard Deviation')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = newData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "data = [company for company in data if 'hist' in company and company['hist'] is not None]\n",
    "random.shuffle(data)\n",
    "\n",
    "\n",
    "test_size = int(len(data) * 0.20)\n",
    "test_data = data[:test_size]\n",
    "train_data = data[test_size:]\n",
    "\n",
    "\n",
    "numeric_imputer = SimpleImputer(strategy='median')\n",
    "robust_scaler = RobustScaler()\n",
    "\n",
    "text_pipeline = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(\n",
    "            max_features=500,\n",
    "            lowercase=True,\n",
    "            ngram_range=(1, 2)\n",
    "        )),\n",
    "        ('svd', TruncatedSVD(n_components=100, random_state=42))\n",
    "    ])\n",
    "\n",
    "#Feature Engineering\n",
    "def get_features(company):\n",
    "    import numpy as np\n",
    "    features = []\n",
    "    \n",
    "    extra = company.get('extra', {})\n",
    "    profitability = extra.get('Profitability', {})\n",
    "    management = extra.get('Management Effectiveness', {})\n",
    "    income_statement = extra.get(\"Income Statement\", {})\n",
    "    balance_sheet = extra.get(\"Balance Sheet\", {})\n",
    "    cash_flow = extra.get(\"Cash Flow Statement\", {})\n",
    "    stock_history = extra.get(\"Stock Price History\", {})\n",
    "    share_stats = extra.get(\"Share Statistics\", {})\n",
    "    \n",
    "    features.append(company.get('current_price', 0) or np.nan)\n",
    "    features.append(company.get('Market Cap', 0) or np.nan)\n",
    "    features.append(company.get('Enterprise Value', 0) or np.nan)\n",
    "    features.append(company.get(\"Trailing P/E\", 0) or np.nan)\n",
    "    features.append(company.get(\"Forward P/E\", 0) or np.nan)\n",
    "    features.append(company.get(\"PEG Ratio (5yr expected)\", 0) or np.nan)\n",
    "    features.append(company.get(\"Price/Sales\", 0) or np.nan)\n",
    "    features.append(company.get(\"Price/Book\", 0) or np.nan)\n",
    "    features.append(company.get(\"Enterprise Value/Revenue\", 0) or np.nan)\n",
    "    features.append(company.get(\"Enterprise Value/EBITDA\", 0) or np.nan)\n",
    "    \n",
    "    # Getting history base pecentage changes with percentage ranges\n",
    "    val = getDataForPercentageRange(company.get(\"hist\"), -100, -80)\n",
    "    features.append(val[0] if val else np.nan)\n",
    "    features.append(val[1] if val and len(val) > 1 else np.nan)\n",
    "    val = getDataForPercentageRange(company.get(\"hist\"), -60, -40)\n",
    "    features.append(val[0] if val else np.nan)\n",
    "    features.append(val[1] if val and len(val) > 1 else np.nan)\n",
    "    val = getDataForPercentageRange(company.get(\"hist\"), -40, -20)\n",
    "    features.append(val[0] if val else np.nan)\n",
    "    features.append(val[1] if val and len(val) > 1 else np.nan)\n",
    "    val = getDataForPercentageRange(company.get(\"hist\"), -20, 0)\n",
    "    features.append(val[0] if val else np.nan)\n",
    "    features.append(val[1] if val and len(val) > 1 else np.nan)\n",
    "    \n",
    "    features.append(float(profitability.get(\"Profit Margin\", 0) or np.nan))\n",
    "    features.append(float(profitability.get(\"Operating Margin  (ttm)\", 0) or np.nan))\n",
    "    \n",
    "    features.append(float(management.get(\"Return on Assets  (ttm)\", 0) or np.nan))\n",
    "    features.append(float(management.get(\"Return on Equity  (ttm)\", 0) or np.nan))\n",
    "    \n",
    "    features.append(float(income_statement.get(\"Revenue  (ttm)\", 0) or np.nan))\n",
    "    features.append(float(income_statement.get(\"Revenue Per Share  (ttm)\", 0) or np.nan))\n",
    "    features.append(float(income_statement.get(\"Quarterly Revenue Growth  (yoy)\", 0) or np.nan))\n",
    "    features.append(float(income_statement.get(\"Gross Profit  (ttm)\", 0) or np.nan))\n",
    "    features.append(float(income_statement.get(\"EBITDA\", 0) or np.nan))\n",
    "    features.append(float(income_statement.get(\"Net Income Avi to Common  (ttm)\", 0) or np.nan))\n",
    "    features.append(float(income_statement.get(\"Diluted EPS  (ttm)\", 0) or np.nan))\n",
    "    features.append(float(income_statement.get(\"Quarterly Earnings Growth  (yoy)\", 0) or np.nan))\n",
    "    features.append(float(balance_sheet.get(\"Total Cash  (mrq)\", 0) or np.nan))\n",
    "    features.append(float(balance_sheet.get(\"Total Cash Per Share  (mrq)\", 0) or np.nan))\n",
    "    features.append(float(balance_sheet.get(\"Total Debt  (mrq)\", 0) or np.nan))\n",
    "    features.append(float(balance_sheet.get(\"Total Debt/Equity  (mrq)\", 0) or np.nan))\n",
    "    features.append(float(balance_sheet.get(\"Current Ratio  (mrq)\", 0) or np.nan))\n",
    "    features.append(float(balance_sheet.get(\"Book Value Per Share  (mrq)\", 0) or np.nan))\n",
    "    features.append(float(cash_flow.get(\"Operating Cash Flow  (ttm)\", 0) or np.nan))\n",
    "    features.append(float(cash_flow.get(\"Levered Free Cash Flow  (ttm)\", 0) or np.nan))\n",
    "    features.append(float(stock_history.get(\"Beta (5Y Monthly)\", 0) or np.nan))\n",
    "    features.append(float(stock_history.get(\"52 Week Range3\", 0) or np.nan))\n",
    "    features.append(float(stock_history.get(\"S&P 500 52-Week Change3\", 0) or np.nan))\n",
    "    features.append(float(stock_history.get(\"52 Week High3\", 0) or np.nan))\n",
    "    features.append(float(stock_history.get(\"52 Week Low3\", 0) or np.nan))\n",
    "    features.append(float(stock_history.get(\"50-Day Moving Average3\", 0) or np.nan))\n",
    "    features.append(float(stock_history.get(\"200-Day Moving Average3\", 0) or np.nan))\n",
    "    features.append(float(share_stats.get(\"Avg Vol (3 month)3\", 0) or np.nan))\n",
    "    features.append(float(share_stats.get(\"Avg Vol (10 day)3\", 0) or np.nan))\n",
    "    features.append(float(share_stats.get(\"Shares Outstanding5\", 0) or np.nan))\n",
    "    features.append(float(share_stats.get(\"Implied Shares Outstanding6\", 0) or np.nan))\n",
    "    features.append(float(share_stats.get(\"Float8\", 0) or np.nan))\n",
    "    features.append(float(share_stats.get(\"% Held by Insiders1\", 0) or np.nan))\n",
    "    features.append(float(share_stats.get(\"% Held by Institutions1\", 0) or np.nan))\n",
    "    features.append(float(share_stats.get(\"Shares Short (12/31/2024)4\", 0) or np.nan))\n",
    "    features.append(float(share_stats.get(\"Short Ratio (12/31/2024)4\", 0) or np.nan))\n",
    "    features.append(float(share_stats.get(\"Short % of Float (12/31/2024)4\", 0) or np.nan))\n",
    "    features.append(float(share_stats.get(\"Short % of Shares Outstanding (12/31/2024)4\", 0) or np.nan))\n",
    "    features.append(float(share_stats.get(\"Shares Short (prior month 11/29/2024)4\", 0) or np.nan))\n",
    "    \n",
    "    return features\n",
    "\n",
    "def get_targets(company):\n",
    "    try:\n",
    "        hist = company['hist']\n",
    "        ranges = [(0, 20), (20, 40), (40, 60), (60, 80), (80, 100), (10, 100)]\n",
    "        lowhigh = []\n",
    "        for r_start, r_end in ranges:\n",
    "            data = getDataForPercentageRange(hist, r_start, r_end)\n",
    "            lowhigh.extend(data[0:2])\n",
    "        if len(lowhigh) != 12 or any(np.isnan(lowhigh)):\n",
    "            return None\n",
    "        return lowhigh\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing targets: {str(e)}\")\n",
    "        return None\n",
    "    \n",
    "# Preprocessing data for training\n",
    "def preprocess_data(data_subset, fit=False):\n",
    "    X_numeric = []\n",
    "    y = []\n",
    "    descriptions = []\n",
    "    \n",
    "    for company in data_subset:\n",
    "        features = get_features(company)\n",
    "        X_numeric.append(features)\n",
    "\n",
    "        targets = get_targets(company)\n",
    "        if targets is None:\n",
    "            continue\n",
    "        y.append(targets)\n",
    "        \n",
    "        desc = str(company.get('company_description', '')).lower()\n",
    "        descriptions.append(desc)\n",
    "    \n",
    "    if fit:\n",
    "        X_numeric = numeric_imputer.fit_transform(X_numeric)\n",
    "        X_numeric = robust_scaler.fit_transform(X_numeric)\n",
    "        X_text = text_pipeline.fit_transform(descriptions)\n",
    "    else:\n",
    "        X_numeric = numeric_imputer.transform(X_numeric)\n",
    "        X_numeric = robust_scaler.transform(X_numeric)\n",
    "        X_text = text_pipeline.transform(descriptions)\n",
    "    X = np.hstack([X_numeric, X_text])\n",
    "    X = np.nan_to_num(X)\n",
    "    \n",
    "    return X, np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction import text\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "\n",
    "data = [company for company in data if 'hist' in company and company['hist'] is not None]\n",
    "random.shuffle(data)\n",
    "\n",
    "test_size = int(len(data) * 0.20)\n",
    "test_data = data[:test_size]\n",
    "train_data = data[test_size:]\n",
    "\n",
    "text_pipeline = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(\n",
    "            max_features=500,\n",
    "            lowercase=True,\n",
    "            ngram_range=(1, 2)\n",
    "        )),\n",
    "        ('svd', TruncatedSVD(n_components=100, random_state=42))\n",
    "    ])\n",
    "robust_scaler = RobustScaler()\n",
    "\n",
    "X_train, y_train = preprocess_data(train_data, fit=True)\n",
    "X_test, y_test = preprocess_data(test_data, fit=False)\n",
    "\n",
    "y_scaler = StandardScaler()\n",
    "y_train = y_scaler.fit_transform(y_train)\n",
    "y_test = y_scaler.transform(y_test)\n",
    "\n",
    "def build_nn_model():\n",
    "    return MultiOutputRegressor(\n",
    "        MLPRegressor(\n",
    "            early_stopping=True,\n",
    "            validation_fraction=0.2,\n",
    "            random_state=42,\n",
    "            max_iter=2000,\n",
    "            solver='adam'\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Neural Network with Grid Search\n",
    "nn_param_grid = {\n",
    "    'estimator__hidden_layer_sizes': [(128,), (256, 128), (128, 64, 32)],\n",
    "    'estimator__activation': ['relu', 'tanh'],\n",
    "    'estimator__alpha': [0.0001, 0.001],\n",
    "    'estimator__learning_rate_init': [0.001, 0.0001]\n",
    "}\n",
    "\n",
    "nn_grid = GridSearchCV(\n",
    "    build_nn_model(),\n",
    "    nn_param_grid,\n",
    "    cv=3,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1\n",
    ")\n",
    "nn_grid.fit(X_train, y_train)\n",
    "best_nn = nn_grid.best_estimator_\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, scaler, name):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_original = scaler.inverse_transform(y_pred)\n",
    "    y_test_original = scaler.inverse_transform(y_test)\n",
    "    \n",
    "    # Flatten the arrays\n",
    "    y_test_flat = y_test_original.ravel()\n",
    "    y_pred_flat = y_pred_original.ravel()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mse = mean_squared_error(y_test_original, y_pred_original)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test_flat, y_pred_flat)\n",
    "    r2 = r2_score(y_test_flat, y_pred_flat)\n",
    "    \n",
    "    print(f\"\\n{name} Performance:\")\n",
    "    print(f\" MSE: {mse:.2f}\")\n",
    "    print(f\" RMSE: {rmse:.2f}\")\n",
    "    print(f\" MAE: {mae:.2f}\")\n",
    "    print(f\" R2: {r2:.2f}\")\n",
    "nn_metrics = evaluate_model(best_nn, X_test, y_test, y_scaler, \"Neural Network\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "\n",
    "xgb_param_grid = {\n",
    "    'estimator__n_estimators': [100, 500, 1000,1500],\n",
    "    'estimator__learning_rate': [0.1,0.001,0.0001],\n",
    "    'estimator__max_depth': [7,12,16],\n",
    "    'estimator__subsample': [0.8, 1.0],\n",
    "    'estimator__colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "xgb_model = MultiOutputRegressor(XGBRegressor(random_state=42))\n",
    "xgb_grid = GridSearchCV(\n",
    "    xgb_model,\n",
    "    xgb_param_grid,\n",
    "    cv=3,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "xgb_grid.fit(X_train, y_train)\n",
    "\n",
    "# Best model for evaluation\n",
    "best_xgb_model = xgb_grid.best_estimator_\n",
    "xgb_metrics = evaluate_model(best_xgb_model, X_test, y_test, y_scaler, \"XGBoost\")\n",
    "\n",
    "# Best parameters for reference\n",
    "print(\"Best XGBoost Parameters:\", xgb_grid.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
